<h2 id="-">수치 예측</h2>

<h3 id="-">선형 회귀</h3>

선형 회귀(Linear Regression)란 종속 변수 y와 한 개 이상의 독립 변수 X와의 선형 상관 관계를 모델링하는 회귀분석 기법이다.
선형 회귀를 수식으로 표현하면 H(x) + Wx + b인데, H(x)는 가설(Hypothesis)을 의미하고 W는 가중치(Weight), b는 편향(bias)를 의미한다.
선형회귀란 바로 이 가중치와 편향을 조절하여 얻은 가설의 값이 실제 값과의 차이가 가장 적은 모델을 찾는 것이다.
<p><img src="/Image/linearRegression.jpg"></p>

<h3 id="-">손실 함수, 경사 하강법</h3>

가설 값이 실제 값과의 차이가 가장 적은지 판단하는 함수를 손실 함수(Loss Function)혹은 비용 함수(Cost Function)라 하는데, 선형회귀에서는 평균제곱오차(MSE)를 이용하여 손실 함수를 구한다. 평균제곱오차를 이용하여 손실 함수를 구하면 아래의 식과 같이 된다. 

<p><img src="/Image/cost_function.png"></p>



<p><img src="/Image/Linear_Regression.png"></p>

<h2 id="-">이진 분류</h2>

<h3 id="-">퍼셉트론</h3>

<h3 id="-">로지스틱 회귀</h3>

<h3 id="-">Sigmoid Function</h3>
